{
 "metadata": {
  "name": "",
  "signature": "sha256:805e554cf7fd01c644d0d3d2829af67ce48c2d0ea280801cb5a394f2c7c168c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd D:/Python/Amadeus-hiring-test/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Python\\Amadeus-hiring-test\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercise 1: reading the number of lines in each file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The tests emphasise the use of the pandas library, so I decided to get familiar with it from the first exercise. I am able to load a single column directly into memory, but am using chunks to allow less powerful machines to run the code.\n",
      "\n",
      "I originally opened the first few lines of each file using the \"nrows\" parameter to get an idea of the dataset. I unpacked the data as it will be accessed multiple time throughout these tests, however pandas allows for compressed data reading using \"compression = bz2\", which could be useful for a basic check like in this test.\n",
      "\n",
      "I have a list of the \"nan\" entries in the searches file, possibly need to account for them in other exercises."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bookings_reader = pd.read_csv('bookings.csv',sep = '^', usecols = ['source'], chunksize = 10000)\n",
      "booking_size = 0\n",
      "for chunk in bookings_reader:\n",
      "    booking_size += chunk.shape[0]\n",
      "    \n",
      "print 'Number of lines in Bookings.csv = ', booking_size "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of lines in Bookings.csv =  10000010\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "searches_reader = pd.read_csv('searches.csv',sep = '^', usecols = ['Country'], chunksize = 10000) #column of chars, data contains nans which gave a warning and forced a float64 dtype when I attempted to load a column of booleans \n",
      "searches_size = 0\n",
      "for chunk in searches_reader:\n",
      "    searches_size += chunk.shape[0]\n",
      "print 'Number of lines in Searches.csv = ', searches_size\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of lines in Searches.csv =  20390198\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}