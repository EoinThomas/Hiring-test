{
 "metadata": {
  "name": "",
  "signature": "sha256:54cb6e13e3e727749c4ed1c7ed51f4e20e36f279c32881567cebbd05a14bff5d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd D:/Python/Amadeus-hiring-test/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Python\\Amadeus-hiring-test\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bonus exercise:  match searches with bookings "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For every search in the searches file, find out whether the search ended up in a booking or not (using the info in the bookings file). For instance, search and booking origin and destination should match. For the bookings file, origin and destination are the columns dep_port and arr_port, respectively. \n",
      "Generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise. \n",
      "\n",
      "1) Date information is also crucial: when was the search made, and for which day (given by boarding time). I will also compare created dates, I noticed the bookings file has a created date and act_date, but this second date appears to differ from cre_date only in cancellations, which I remove from the bookings list.\n",
      "\n",
      "2) Bookings rows are only one way, which means return trips could be incorrectly matched to searches, and should thus be removed. I tried several options, but finally am using a comparison of dep_port to off_port, where dep_port is the original departure port of the booking, and off_port is the destination of the specific trip. If these are equal then the journey is the return leg of a booking, and should be removed from bookings. This reduces the size of bookings by ~1/2 in combination with the cancellations removal.\n",
      "\n",
      "3) Duplicate entries. I need to investigate whether the duplicates I can see (in both datasets) are due to unrestrictive matching or are there simply duplicates in the database. Multiple searches which usually occur on the same day are sometimes associated with a single booking. Currently, all these searches will be counted as \"booked\". Sometimes a single search will be matched to multiple bookings, indicating that the matching is not completely accurate using the current criteria."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load bookings, remove cancellations and format column names and entries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_dataframes = pd.DataFrame()\n",
      "bookings_reader = pd.read_csv('bookings.csv',chunksize = 5000000,sep = '^', usecols=['cre_date           ','brd_time           ','dep_port','arr_port','pax','off_port'])\n",
      "\n",
      "for data_bookings in bookings_reader:\n",
      "    data_bookings.rename(columns={'cre_date           ': 'booked_date','brd_time           ':'brd_date' }, inplace=True)\n",
      "\n",
      "    data_bookings = data_bookings[data_bookings.pax >0]; # Remove cancellations as these will not match a search\n",
      "    data_bookings.pop('pax');\n",
      "\n",
      "    data_bookings = data_bookings[data_bookings.dep_port != data_bookings.off_port]; # Remove return leg of roundtrips\n",
      "    data_bookings.pop('off_port');\n",
      "\n",
      "    # Clean up strings for comparison\n",
      "    data_bookings.booked_date = data_bookings.booked_date.str.slice(start = 0,stop = 10)\n",
      "    data_bookings.dep_port = data_bookings.dep_port.str.slice(start = 0,stop = 3)\n",
      "    data_bookings.arr_port = data_bookings.arr_port.str.slice(start = 0,stop = 3)\n",
      "    data_bookings.brd_date = data_bookings.brd_date.str.slice(start = 0,stop = 10)\n",
      "\n",
      "    num_searches = 0;\n",
      "    searches_reader = pd.read_csv('searches.csv',chunksize=2000000,sep = '^', usecols=['Date','Origin', 'Destination','Seg1Date'])\n",
      "    for data_searches in searches_reader:\n",
      "        data_searches.index = data_searches.index+num_searches\n",
      "        num_searches+= data_searches.shape[0]\n",
      "        data_searches.rename(columns={'Date':'searched_date','Origin': 'dep_port', 'Destination':'arr_port','Seg1Date':'brd_date'}, inplace=True) \n",
      "        merged_dataframes = merged_dataframes.append(pd.merge(data_searches,data_bookings,on=['dep_port','arr_port','brd_date'], right_index = True, how='inner'))\n",
      "        \n",
      "del data_searches, data_bookings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "265.664033307\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp=merged_dataframes.index.unique() #print number of matches prior to date check\n",
      "print tmp.shape[0]\n",
      "del tmp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "346832\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I check that the search occured prior to the booking and remove matches with bookings which happened before the search. Parsing the dates is time consuming, so this check is performed last."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_dataframes.searched_date = pd.to_datetime(merged_dataframes.searched_date,format = '%Y-%m-%d')\n",
      "merged_dataframes.booked_date = pd.to_datetime(merged_dataframes.booked_date,format = '%Y-%m-%d')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_dataframes = merged_dataframes[merged_dataframes.searched_date <= merged_dataframes.booked_date]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "booked_search_indices = merged_dataframes.index.unique() #multiple bookings pointed at by single search\n",
      "num_booked = booked_search_indices.shape[0]\n",
      "pct_booked = 100*float(num_booked)/num_searches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'This script identified ', num_booked, ' matches.'\n",
      "print 'This corresponds to {0:.1f}% of all searches.'.format(pct_booked) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This script identified  346832  matches.\n",
        "This corresponds to 1.7% of all searches.\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write booked_search_indices to .csv\n",
      "\n",
      "#generate new DF with single column  \n",
      "\n",
      "#df.to_csv(f, mode='a', header=False)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}